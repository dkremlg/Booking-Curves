{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.python.ops import confusion_matrix\n",
    "from tensorflow.python.ops import math_ops\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data=pd.read_csv('C:/Users/dkoch/Documents/tensorflow/R_Input.csv')\n",
    "Data=pd.read_csv('R_Input.csv')\n",
    "Data=Data.fillna(0)\n",
    "\n",
    "Data['dprio0']=Data['dprio']**0\n",
    "#Data['dprio2']=Data['dprio']**2\n",
    "#Data['dprio3']=Data['dprio']**3\n",
    "Data=Data.rename(columns={'dprio': 'dprio1'})\n",
    "Data['pax_total']=Data['pax_total'].apply(lambda x: x if x>0 else 0)\n",
    "Data['pax_total']=Data['pax_total']-Data['group_pax']\n",
    "\n",
    "\n",
    "direction=pd.get_dummies(Data['direction'],drop_first=True)\n",
    "direction.columns=['direction:'+x for x in direction.columns]\n",
    "\n",
    "whichholiday_left_LUX=pd.get_dummies(Data['whichholiday_left_LUX'],drop_first=True)\n",
    "whichholiday_left_LUX.columns=['whichholiday_left_LUX:'+x for x in whichholiday_left_LUX.columns]\n",
    "\n",
    "whichholiday_right_LUX=pd.get_dummies(Data['whichholiday_right_LUX'],drop_first=True)\n",
    "whichholiday_right_LUX.columns=['whichholiday_right_LUX:'+x for x in whichholiday_right_LUX.columns]\n",
    "\n",
    "Data=pd.concat([Data,direction,whichholiday_left_LUX,whichholiday_right_LUX],axis=1)\n",
    "\n",
    "Data.index=Data['calendar_date']+'_'+Data['direction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "dprio=Data[['dprio'+str(i) for i in range(0,2)]].drop_duplicates().transpose()\n",
    "dprio.columns=range(365,-1,-1)\n",
    "dprio=dprio[[x for x  in range(0,366)]]\n",
    "\n",
    "X_data=Data.drop_duplicates(subset=['calendar_date','direction'])[[x for x in Data.columns if 'direction:' in x]\\\n",
    "+[x for x in Data.columns if 'whichholiday_left_LUX:' in x]\\\n",
    "+[x for x in Data.columns if 'whichholiday_right_LUX:' in x]\\\n",
    "+['holiday_from_left_LUX','holiday_from_right_LUX','holiday_to_left_LUX','holiday_to_right_LUX']\\\n",
    "+['pax_total']]\n",
    "\n",
    "Data['concat']=Data['calendar_date']+'_'+Data['direction']\n",
    "y_data=Data[['concat','dprio1','pax_total']].pivot(index='concat',columns='dprio1',values='pax_total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_data.loc[[x for x in X_data.index if '2019' not in x],:]\n",
    "X_test=X_data.loc[[x for x in X_data.index if '2019' in x],:]\n",
    "y_train=y_data.loc[[x for x in y_data.index if '2019' not in x],:]\n",
    "y_test=y_data.loc[[x for x in y_data.index if '2019' in x],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.3, random_state=1)\n",
    "\n",
    "X_train=X_train.values\n",
    "X_test=X_test.values\n",
    "y_train=y_train.values\n",
    "y_test=y_test.values\n",
    "#dprio.loc['dprio0',:]=dprio.loc['dprio0',:]/365\n",
    "#dprio.loc['dprio1',:]=1*(dprio.loc['dprio1',:]/365)\n",
    "dprio=dprio.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input=X_train.shape[1]\n",
    "n_hidden_1=n_input*2\n",
    "n_hidden_2=2\n",
    "n_output=y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Input 'b' of 'MatMul' Op has type int8 that does not match type float32 of argument 'a'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    510\u001b[0m                 \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_ref\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m                 preferred_dtype=default_dtype)\n\u001b[0m\u001b[0;32m    512\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, ctx, accept_symbolic_tensors)\u001b[0m\n\u001b[0;32m   1174\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1175\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_TensorTensorConversionFunction\u001b[1;34m(t, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m    976\u001b[0m         \u001b[1;34m\"Tensor conversion requested dtype %s for Tensor with dtype %s: %r\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 977\u001b[1;33m         (dtype.name, t.dtype.name, str(t)))\n\u001b[0m\u001b[0;32m    978\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Tensor conversion requested dtype float32 for Tensor with dtype int8: 'Tensor(\"Placeholder_86:0\", shape=(2, 366), dtype=int8)'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-211-54756506a83d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;31m# Model Outputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m \u001b[0myhat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mforward_propagation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mZ\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-211-54756506a83d>\u001b[0m in \u001b[0;36mforward_propagation\u001b[1;34m(x, z)\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;31m# Output fully connected layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;31m#out_layer=tf.add(tf.matmul(layer_2, weights['out']),biases['out'])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m     \u001b[0mout_layer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m     \u001b[0mout_layer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_layer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mout_layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[1;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[0;32m   2453\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2454\u001b[0m       return gen_math_ops.mat_mul(\n\u001b[1;32m-> 2455\u001b[1;33m           a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n\u001b[0m\u001b[0;32m   2456\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2457\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[1;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[0;32m   5330\u001b[0m   _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m   5331\u001b[0m         \u001b[1;34m\"MatMul\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtranspose_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtranspose_b\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5332\u001b[1;33m                   name=name)\n\u001b[0m\u001b[0;32m   5333\u001b[0m   \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5334\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    545\u001b[0m                   \u001b[1;34m\"%s type %s of argument '%s'.\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m                   (prefix, dtypes.as_dtype(attrs[input_arg.type_attr]).name,\n\u001b[1;32m--> 547\u001b[1;33m                    inferred_from[input_arg.type_attr]))\n\u001b[0m\u001b[0;32m    548\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m           \u001b[0mtypes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Input 'b' of 'MatMul' Op has type int8 that does not match type float32 of argument 'a'."
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "learning_rate = 10\n",
    "training_epochs = 100\n",
    "\n",
    "X = tf.placeholder(\"float\", [None, n_input])\n",
    "Z = tf.placeholder(\"float\", [2, 366])\n",
    "y = tf.placeholder(\"float\", [None, n_output])\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "# Dictionary of Weights and Biases\n",
    "weights = {\n",
    "  'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1],mean=0,stddev=0.001)),\n",
    "  'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2],mean=0,stddev=0.001)),\n",
    "  #'out': tf.Variable(tf.random_normal([n_hidden_2, n_output]))\n",
    "  #'out': tf.Variable(dprio.reshape(4,366),dtype=tf.float32)  \n",
    "}\n",
    "\n",
    "biases = {\n",
    "  'b1': tf.Variable(tf.random_normal([n_hidden_1],mean=0,stddev=0.001)),\n",
    "  'b2': tf.Variable(tf.random_normal([n_hidden_2],mean=0,stddev=0.001)),\n",
    "  #'out': tf.Variable(tf.random_normal([n_output]))\n",
    "}\n",
    "\n",
    "# Model Forwar§d Propagation step\n",
    "def forward_propagation(x,z):\n",
    "    # Hidden layer1\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    #layer_1 = tf.tanh(layer_1)\n",
    "    \n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    #layer_2 = tf.tanh(layer_2)\n",
    "\n",
    "    # Output fully connected layer\n",
    "    #out_layer=tf.add(tf.matmul(layer_2, weights['out']),biases['out'])\n",
    "    out_layer = tf.matmul(layer_2, z)\n",
    "    out_layer = tf.exp(out_layer)\n",
    "    return out_layer\n",
    "\n",
    "\n",
    "# Model Outputs\n",
    "yhat = forward_propagation(X,Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.square(yhat-y))\n",
    "# our mean squared error cost function\n",
    "#train = tf.train.GradientDescentOptimizer(0.001).minimize(cost)\n",
    "\n",
    "#cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=yhat))\n",
    "#cost=tf.losses.mean_squared_error(y, yhat)\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_t=[]\n",
    "c_test=[]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Initiate session and initialize all vaiables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver = tf.train.Saver()\n",
    "    #saver.restore(sess,'yahoo_dataset.ckpt')\n",
    "    for epoch in range(100):\n",
    "        for i in range(358):\n",
    "            for j in range(X_train.shape[0]):\n",
    "                sess.run(train,feed_dict={X:X_train[j].reshape(1,16), y:y_train[j].reshape(1,366), Z:dprio.reshape(2,366)})\n",
    "            # Run cost and train with each sample\n",
    "        c_t.append(sess.run(cost, feed_dict={X:X_train,y:y_train,Z:dprio.reshape(2,366)}))\n",
    "        c_test.append(sess.run(cost, feed_dict={X:X_test,y:y_test,Z:dprio.reshape(2,366)}))\n",
    "        print('Epoch :',epoch,'Cost :',c_t[epoch])\n",
    "        pred = sess.run(yhat, feed_dict={X:X_test,Z:dprio.reshape(2,366)})\n",
    "        print(pred)\n",
    "#     y_test = denormalize(df_test,y_test)\n",
    "#     pred = denormalize(df_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
